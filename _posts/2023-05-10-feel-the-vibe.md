---
layout: post
title: Feel the Vibe (Emotion Recognition)
subtitle: Samuel Leong and Alex Strasser
# cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/feel_the_vibe_1.jpg
# share-img: /assets/img/path.jpg
tags: [spring_23]
---
Wearables are getting increasingly popular and feasible as computing power becomes smaller and more powerful. Indeed, the advent of advanced sensors and intelligence being packed into smaller packages opens up new opportunities for novel applications. In "Feel the Vibe", we aim to create a wearable that is able to display the emotion from speech in the form of an RGB Neopixel Ring that changes colors based on the detected emotion.

Applications include: being used as an assistive device for autistic or deaf people in detecting tones in someone else's voice; or as a fashion item such as a bracelet, earrings, hat, tie, belt, or shirt. It is noted that embedded deep learning devices are perfect for this application, not only due to the small form factor required for wearables, but also because local processing of audio preserves privacy. 
<p align="center"> <img src="/assets/img/feel_the_vibe_1.jpg" width="80%" height="80%"> </p>
-- [**Vido demos**](https://drive.google.com/drive/folders/1FkTV6bVdnSQwW8d_BE3ZR1clQhGaDDNH?usp=share_link)
